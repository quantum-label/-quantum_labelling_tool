{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup process started for http://backup.healthdataportal.eu/\n",
      "Found 12 catalogues.\n",
      "Catalogue: Saving Associated National HDABies.. with 2 datasets.\n",
      "Catalogue: Saving Belgian National HDAB.. with 8 datasets.\n",
      "Distribution: Saving: Antimicrobial Resistance -Test..\n",
      "Distribution: Saving: Belgian Health Data Agency..\n",
      "Sample: Saving: Proxy data generating for the EHDS2 Pilot project Sciensano Use Case..\n",
      "Sample: Saving: ID_TU_STATBEL_POP..\n",
      "Analytics: Saving: Technical report number of unique study subjects available by environment for project HDBP0250..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#duration, Converter=<function parse_duration at 0x0000019927874EE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unable to parse duration string 'NA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Saving: Next Generation Sequencing..\n",
      "Sample: Saving: Next Generation Sequencing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000019927874820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isodates.py\", line 203, in parse_date\n",
      "    raise ISO8601Error('Unrecognised ISO 8601 date format: %r' % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unrecognised ISO 8601 date format: '6/17/2021'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: Saving: Metadata - Precision central MAB..\n",
      "Sample: Saving: Metadata - Precision local MAB..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000019927874820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isodates.py\", line 203, in parse_date\n",
      "    raise ISO8601Error('Unrecognised ISO 8601 date format: %r' % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unrecognised ISO 8601 date format: '?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Saving: Precision_Treatment..\n",
      "Sample: Saving: Precision_Treatment..\n",
      "Catalogue: Saving Cancer Registry examples.. with 2 datasets.\n",
      "Sample: Saving: Data structure description..\n",
      "Analytics: Saving: Krebserkrankungen in ÃÂsterrreich 2022..\n",
      "Analytics: Saving: Dashboard for querying cancer data..\n",
      "Catalogue: Saving Croatian National HDAB.. with 7 datasets.\n",
      "Distribution: Saving: Request for access to public health data..\n",
      "Catalogue: Saving Danish National HDAB.. with 13 datasets.\n",
      "Catalogue: Saving EU datasets.. with 3 datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#duration, Converter=<function parse_duration at 0x0000019927874EE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unable to parse duration string 'year'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Saving: Union data access service..\n",
      "Sample: Saving: AMR metadata..\n",
      "Analytics: Saving: Surveillance Atlas of Infectious Diseases..\n",
      "Distribution: Saving: CRC-Cohort..\n",
      "Sample: Saving: CRC-Cohort..\n",
      "Catalogue: Saving Finnish National HDAB.. with 11 datasets.\n",
      "Distribution: Saving: Findata..\n",
      "Sample: Saving: Variable and code list descriptions in Finnish Data resources catalogue...\n",
      "Analytics: Saving: Population by age group in Terveys-Hilmo..\n",
      "Distribution: Saving: Metadata description including variable descriptions in the Finnish Data Resources Catalogue..\n",
      "Distribution: Saving: Metadata description including variable descriptions in the Finnish Data Resources Catalogue..\n",
      "Distribution: Saving: Metadata description including variable level description in Finnish Data resources catalogue..\n",
      "Distribution: Saving: Metadata description including variable level description in the Finnish Data resources catalogue..\n",
      "Distribution: Saving: Metadata description in the Finnish Data Resources Catalogue..\n",
      "Distribution: Saving: Metadata description in the Finnish Data Resources Catalogue..\n",
      "Analytics: Saving: Quality report of the Vaccination register..\n",
      "Distribution: Saving: Metadata description including variable descriptions in the Finnish Data Resources Catalogue..\n",
      "Analytics: Saving: ICD-10 diagnoses of healthcare outpatient care by municipality and welfare area..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#dateTime, Converter=<function parse_datetime at 0x0000019927874D30>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isodatetime.py\", line 51, in parse_datetime\n",
      "    datestring, timestring = datetimestring.split('T')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isodatetime.py\", line 53, in parse_datetime\n",
      "    raise ISO8601Error(\"ISO 8601 time designator 'T' missing. Unable to\"\n",
      "isodate.isoerror.ISO8601Error: ISO 8601 time designator 'T' missing. Unable to parse datetime string '1.1.2021'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Saving: Metadata description including variable level description in the Finnish Data Resources Catalogue..\n",
      "Analytics: Saving: Data Resource Profile..\n",
      "Catalogue: Saving French National HDAB.. with 2 datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000019927874820>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"C:\\Users\\ChVa5406\\AppData\\Roaming\\Python\\Python310\\site-packages\\isodate\\isodates.py\", line 203, in parse_date\n",
      "    raise ISO8601Error('Unrecognised ISO 8601 date format: %r' % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unrecognised ISO 8601 date format: '_g_L46C3063'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue: Saving Hungarian National HDAB.. with 3 datasets.\n",
      "Catalogue: Saving Norwegian National HDAB.. with 12 datasets.\n",
      "Distribution: Saving: Core variables - additional..\n",
      "Distribution: Saving: Core variables - diagnostics and primary treatment..\n",
      "Distribution: Saving: National Clinical Registry for Colorectal Cancer..\n",
      "Distribution: Saving: Medisinsk fÃÂ¸dselsregister..\n",
      "Analytics: Saving: Statistikkbank MFR..\n",
      "Distribution: Saving: DÃÂ¸dsÃÂ¥rsaksregisteret..\n",
      "Analytics: Saving: DÃÂ¸dsÃÂ¥rsaksregisterets statistikkbank..\n",
      "Distribution: Saving: Norwegian Surveillance System for Communicable Diseases..\n",
      "Distribution: Saving: Norwegian Patient Registry..\n",
      "Analytics: Saving: Aktivitet i somatiske sykehus, spesialisthelsetjenesten..\n",
      "Distribution: Saving: Prescription register..\n",
      "Sample: Saving: List of variables for the prescription registry..\n",
      "Distribution: Saving: StatBank Norway..\n",
      "Distribution: Saving: Troms 1-7..\n",
      "Catalogue: Saving Slovenian Catalogue.. with 1 datasets.\n",
      "Catalogue: Saving Testing.. with 3 datasets.\n",
      "Distribution: Saving: test..\n",
      "Analytics: Saving: test..\n",
      "Backup done!\n"
     ]
    }
   ],
   "source": [
    "# Get all metadata structure from FDP using the API\n",
    "# V1.2\n",
    "\n",
    "import requests\n",
    "import rdflib\n",
    "from rdflib import Graph, Literal, Namespace, URIRef, BNode\n",
    "import os \n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Format the current date as YYYY-MM-DD\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "LDP = Namespace('http://www.w3.org/ns/ldp#')\n",
    "RDF = Namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#')\n",
    "DCT = Namespace('http://purl.org/dc/terms/')\n",
    "DCAT = Namespace('http://www.w3.org/ns/dcat#')\n",
    "ADMS = Namespace('http://www.w3.org/ns/adms#')\n",
    "HEALTHDCATAP = Namespace('http://healthdataportal.eu/ns/health#')\n",
    "\n",
    "# Modify here the FDP API URL\n",
    "# fdpURL = \"http://ehelse.healthdataportal.eu/\"\n",
    "# fdpURL = \"http://fdp1.healthdataportal.eu/\"\n",
    "fdpURL = \"http://backup.healthdataportal.eu/\"\n",
    "\n",
    "# Create a folder to save the files\n",
    "folder_name = f'FDP-Backup-{today_date}'\n",
    "current_directory = os.getcwd()\n",
    "folder_path = os.path.join(current_directory, folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "print(f'Backup process started for {fdpURL}')\n",
    "\n",
    "# Function to sanitize file and folder names\n",
    "def sanitize_filename(name):\n",
    "    name = re.sub(r'@.*', '', name)  # Remove any character after @, including the @\n",
    "    name = re.sub(r'[^A-Za-z0-9-_ ]', '', name)  # Remove any character that is not a letter, number, hyphen, underscore, or space\n",
    "    name = name.replace(' ', '_')  # Replace spaces with underscores\n",
    "    return name.strip().lower()  # Trim leading and trailing whitespace\n",
    "\n",
    "\n",
    "# Get all catalogues\n",
    "\n",
    "headers = {'Accept': 'text/turtle'}\n",
    "res=requests.get(url=fdpURL, headers=headers)\n",
    "\n",
    "fdpStore = Graph()\n",
    "fdpStore.parse(data=res.text, format=\"turtle\")\n",
    "\n",
    "for catalogue in fdpStore.subjects(RDF.type, LDP.DirectContainer):\n",
    "    allCatalogues = list(fdpStore.objects(catalogue, LDP.contains))\n",
    "\n",
    "filename = 'FDP.ttl'  # Make sure this is a valid filename\n",
    "full_path = os.path.join(folder_path, filename)\n",
    "fdpStore.serialize(full_path, format=\"turtle\")\n",
    "\n",
    "\n",
    "print(f'Found {len(allCatalogues)} catalogues.')\n",
    "\n",
    "# Get catalogue\n",
    "for index, catalogue in enumerate(allCatalogues):\n",
    "\n",
    "    #if index > 0:\n",
    "    #    break\n",
    "    \n",
    "    catalogueStore = Graph()\n",
    "\n",
    "    try:\n",
    "        resCatalogue = requests.get(url=catalogue, headers=headers).text  \n",
    "        catalogueStore.parse(data=resCatalogue, format=\"turtle\")\n",
    "        fdpStore += catalogueStore # merge graph \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing catalogue {catalogue}: {e}\")\n",
    "        continue  # Skip to next catalogue\n",
    "\n",
    "    # Extracting and saving catalogue details\n",
    "    for catalogue in catalogueStore.subjects(RDF.type, DCAT.Catalog):\n",
    "        catalogueTitles = list(catalogueStore.objects(catalogue, DCT.title))\n",
    "        allDatasets = list(catalogueStore.objects(catalogue, DCAT.dataset))\n",
    "        print(f\"Catalogue: Saving {catalogueTitles[0]}.. with {len(allDatasets)} datasets.\")\n",
    "    \n",
    "\n",
    "    if catalogueTitles:\n",
    "        catalogue_title = sanitize_filename(str(catalogueTitles[0]))\n",
    "    else:\n",
    "        catalogue_title = index\n",
    "\n",
    "    # Create a subfolder for the catalogue\n",
    "    catalogue_folder = os.path.join(folder_path, f'catalogue_{catalogue_title}')\n",
    "    if not os.path.exists(catalogue_folder):\n",
    "        os.makedirs(catalogue_folder)\n",
    "        \n",
    "    # Save the catalogue RDF file\n",
    "    catalogue_file = os.path.join(catalogue_folder, f'catalogue_{catalogue_title}.ttl')\n",
    "    catalogueStore.serialize(catalogue_file, format=\"turtle\")\n",
    "\n",
    "    # Iterating datasets within the catalogue\n",
    "    for dataset in allDatasets:\n",
    "        datasetStore = Graph()\n",
    "        \n",
    "        try:\n",
    "            resDataset = requests.get(url=dataset, headers=headers).text\n",
    "            datasetStore.parse(data=resDataset, format=\"turtle\")\n",
    "            fdpStore += datasetStore # merge graph \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get content for {dataset}\")\n",
    "            continue  # Skip to next dataset\n",
    "        \n",
    "        datasetTitles = []\n",
    "        for datasetClass in datasetStore.subjects(RDF.type, DCAT.Dataset):\n",
    "            datasetTitles = list(datasetStore.objects(datasetClass, DCT.title))\n",
    "            allDistributions = list(datasetStore.objects(datasetClass, DCAT.distribution))\n",
    "            allSamples = list(datasetStore.objects(datasetClass, ADMS.sample))\n",
    "            allAnalytics = list(datasetStore.objects(datasetClass, HEALTHDCATAP.analytics))\n",
    "\n",
    "        # Iterating through datasets' components: distributions, samples, analytics\n",
    "        datasetSubClasses = [('distribution', allDistributions, DCAT.Distribution),\n",
    "                            ('sample', allSamples, ADMS.Sample),\n",
    "                            ('analytics', allAnalytics, HEALTHDCATAP.Analytics)]\n",
    "\n",
    "        for dcatPropertyName, allItems, dcatClass in datasetSubClasses:\n",
    "            for item in allItems:\n",
    "                tempStore = Graph()\n",
    "                try:\n",
    "                    resSubClassDataset = requests.get(url=item, headers=headers).text\n",
    "                    tempStore.parse(data=resSubClassDataset, format=\"turtle\")\n",
    "                    for compClass in tempStore.subjects(RDF.type, dcatClass):\n",
    "                        compTitles = list(tempStore.objects(compClass, DCT.title))\n",
    "                        print(f\"{dcatPropertyName.capitalize()}: Saving: {compTitles[0]}..\")\n",
    "                    datasetStore += tempStore  # Merge graph\n",
    "                    fdpStore += tempStore # merge graph \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {dcatPropertyName} {item}: {e}\")\n",
    "            \n",
    "        if datasetTitles:\n",
    "            dataset_title = sanitize_filename(str(datasetTitles[0]))\n",
    "        else:\n",
    "            dataset_title = index\n",
    "            \n",
    "        # export a RDF turtle file each cataiogue with associated datasets, distributions, samples, analytics\n",
    "        dataset_file = os.path.join(catalogue_folder, f'dataset_{dataset_title}.ttl')\n",
    "        datasetStore.serialize(dataset_file, format=\"turtle\")\n",
    "\n",
    "print('Backup done!')\n",
    "\n",
    "# Download all TTL in one file\n",
    "\n",
    "fdpStore.serialize('all_content.ttl', format=\"turtle\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N75e250a515194480838b52d4cc2d8d6f (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
